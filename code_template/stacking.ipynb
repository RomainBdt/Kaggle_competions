{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation stacking for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "def plot_predictions_errors(y, y_pred, title):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y,\n",
    "        y_pred=y_pred,\n",
    "        kind=\"actual_vs_predicted\",\n",
    "        subsample=100,\n",
    "        ax=axs[0],\n",
    "        random_state=0,\n",
    "    )\n",
    "    axs[0].set_title(\"Actual vs. Predicted values\")\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y,\n",
    "        y_pred=y_pred,\n",
    "        kind=\"residual_vs_predicted\",\n",
    "        subsample=1000,\n",
    "        ax=axs[1],\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV stacking: \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "regressors = {\n",
    "    'LGBMRegressor11': LGBMRegressor(random_state=SEED, n_jobs=-1, boosting_type='gbdt', num_leaves=48, \n",
    "                                     max_depth=14, learning_rate=0.08, n_estimators=240, subsample=0.7, colsample_bytree=0.6),\n",
    "    'XGBRegressor6': XGBRegressor(random_state=SEED, n_jobs=-1, learning_rate=0.055, n_estimators=200, \n",
    "                                  max_depth=8, min_child_weight=1, gamma=0.07, colsample_bytree=0.67, \n",
    "                                  colsample_bylevel=0.67, colsample_bynode=0.8, subsample=0.7, objective='reg:squarederror'),\n",
    "    'CatBoostRegressor': CatBoostRegressor(random_state=SEED, silent=True), # Promising but fails on the cv\n",
    "    'HistGradientBoostingRegressor3': HistGradientBoostingRegressor(random_state=SEED, max_iter=1000, \n",
    "                                                                    max_depth=10, learning_rate=0.1, \n",
    "                                                                    l2_regularization=0.1, max_leaf_nodes=100, \n",
    "                                                                    min_samples_leaf=20, max_bins=255),\n",
    "}\n",
    "\n",
    "meta_regressors = [\n",
    "    ('LinearRegression', LinearRegression()),\n",
    "    ('RidgeCV', RidgeCV(alphas=np.logspace(-3, 3, 13), cv=cv)),\n",
    "    ('ElasticNetCV', ElasticNetCV(alphas=np.logspace(-3, 3, 13), cv=cv, l1_ratio=[.1, .5, .7, .9, .95, .99, 1], max_iter=100000)),\n",
    "    # ('LassoCV', LassoCV(alphas=np.logspace(-3, 3, 13), cv=cv, max_iter=100000)),  # = ElasticNetCV with l1_ratio=1\n",
    "    # ('LarsCV', LarsCV(cv=cv, max_iter=100000, n_jobs=-1)),\n",
    "    # ('OrthogonalMatchingPursuitCV', OrthogonalMatchingPursuitCV(cv=cv, n_jobs=-1)),\n",
    "    # ('LassoLarsCV', LassoLarsCV(cv=cv, max_iter=10000, n_jobs=-1)),\n",
    "    # ('BayesianRidge', BayesianRidge()),\n",
    "]\n",
    "\n",
    "FIT_REGRESSORS = False\n",
    "DISPLAY_REGRESSOR_RESULTS = True\n",
    "PLOT_ERRORS = False\n",
    "TARGET_TRANSFORMATION = False\n",
    "\n",
    "if FIT_REGRESSORS:\n",
    "    # Store out of fold predictions for meta learner\n",
    "    X_meta_trains = {}  # Dict of datasets used for meta learner training\n",
    "    X_meta_hold_outs = {}  # Dict of datasets used for meta learner validation\n",
    "    X_meta_tests = {}  # Dict of datasets used for meta learner testing\n",
    "\n",
    "for i, (train_index, hold_out_index) in enumerate(cv.split(X_train_prep)):\n",
    "    t0 = time.time()\n",
    "    print(f'Fold {i+1} of {cv.get_n_splits()}')\n",
    "    X_train_cv, X_hold_out = X_train_prep.iloc[train_index].copy(), X_train_prep.iloc[hold_out_index].copy()\n",
    "    y_train_cv, y_hold_out = y_train.iloc[train_index].copy(), y_train.iloc[hold_out_index].copy()\n",
    "    \n",
    "    X_meta_train = pd.DataFrame(index=train_index, columns=[name for name, _ in regressors.items()])\n",
    "    X_meta_hold_out = pd.DataFrame(index=hold_out_index, columns=[name for name, _ in regressors.items()])\n",
    "    X_meta_test = pd.DataFrame(index=X_test_prep.index, columns=[name for name, _ in regressors.items()])\n",
    "    \n",
    "    if FIT_REGRESSORS:\n",
    "        # for name, regressor in regressors:\n",
    "        for name, regressor in regressors.items():\n",
    "            print(f'Fitting {name} ...')\n",
    "            if TARGET_TRANSFORMATION:\n",
    "                ttr = TransformedTargetRegressor(regressor=regressor, func=target_transform, inverse_func=inverse_target_transform, check_inverse=False)\n",
    "            else:\n",
    "                ttr = regressor\n",
    "            \n",
    "            if name == 'CatBoostRegressor':\n",
    "                X_meta_train[name] = cross_val_predict(ttr, X_train_cv, y_train_cv, cv=cv, verbose=0)  # CatBoostRegressor fails on n_jobs=-1\n",
    "            else:\n",
    "                X_meta_train[name] = cross_val_predict(ttr, X_train_cv, y_train_cv, cv=cv, n_jobs=-1, verbose=0)\n",
    "            \n",
    "            # fit the model on the full cv training set\n",
    "            ttr.fit(X_train_cv, y_train_cv)\n",
    "            X_meta_hold_out[name] = ttr.predict(X_hold_out)\n",
    "            X_meta_test[name] = ttr.predict(X_test_prep)\n",
    "\n",
    "            if DISPLAY_REGRESSOR_RESULTS:\n",
    "                print(f'Hold out score of {name}: {mean_squared_error(y_hold_out, X_meta_hold_out[name], squared=False):.4f}')\n",
    "                if not SUBMIT:\n",
    "                    print(f'Test score of {name}: {mean_squared_error(y_test, X_meta_test[name], squared=False):.4f}')\n",
    "\n",
    "        # Store datasets for meta learner\n",
    "        X_meta_trains[i] = X_meta_train.copy()\n",
    "        X_meta_hold_outs[i] = X_meta_hold_out.copy()\n",
    "        X_meta_tests[i] = X_meta_test.copy()\n",
    "        \n",
    "    # Transform the predictions of regressors with target transform\n",
    "    if TARGET_TRANSFORMATION:  \n",
    "        X_meta_train = target_transform(X_meta_trains[i])\n",
    "        X_meta_hold_out = target_transform(X_meta_hold_outs[i])\n",
    "        X_meta_test = target_transform(X_meta_tests[i])\n",
    "    else:\n",
    "        X_meta_train = X_meta_trains[i]\n",
    "        X_meta_hold_out = X_meta_hold_outs[i]\n",
    "        X_meta_test = X_meta_tests[i]\n",
    "\n",
    "    for name, meta_regressor in meta_regressors:\n",
    "        # Fit the final estimator on the hold out predictions\n",
    "        if TARGET_TRANSFORMATION:\n",
    "            meta_ttr = TransformedTargetRegressor(\n",
    "                meta_regressor,\n",
    "                func=target_transform, inverse_func=inverse_target_transform, check_inverse=False)\n",
    "        else:\n",
    "            meta_ttr = meta_regressor\n",
    "        \n",
    "        meta_ttr.fit(X_meta_train, y_train_cv)\n",
    "        y_hold_out_pred = meta_ttr.predict(X_meta_hold_out)\n",
    "        y_test_pred = meta_ttr.predict(X_meta_test)\n",
    "        \n",
    "        if not SUBMIT:\n",
    "            score_eval = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "        else:\n",
    "            score_eval = np.nan\n",
    "        \n",
    "        l1_ratio = getattr(meta_ttr.regressor_, 'l1_ratio_', np.nan) if TARGET_TRANSFORMATION else getattr(meta_ttr, 'l1_ratio_', np.nan)\n",
    "        alpha = getattr(meta_ttr.regressor_, 'alpha_', np.nan) if TARGET_TRANSFORMATION else getattr(meta_ttr, 'alpha_', np.nan)\n",
    "        coef = getattr(meta_ttr.regressor_, 'coef_', np.nan) if TARGET_TRANSFORMATION else getattr(meta_ttr, 'coef_', np.nan)\n",
    "        intercept = getattr(meta_ttr.regressor_, 'intercept_', np.nan) if TARGET_TRANSFORMATION else getattr(meta_ttr, 'intercept_', np.nan)\n",
    "        \n",
    "        print(f'Meta regressor: {name}, RMSE hold out: {mean_squared_error(y_hold_out, y_hold_out_pred, squared=False)},',\n",
    "              f'RMSE test: {score_eval:.4f}, fit time: {time.time() - t0:.2f} s,',\n",
    "              f'Coefficients: {coef}, intercept: {intercept}, l1_ratio: {l1_ratio}, alpha: {alpha}', end='\\n'\n",
    "        )\n",
    "        if PLOT_ERRORS:\n",
    "            plot_predictions_errors(y_hold_out, y_hold_out_pred, 'Hold out')\n",
    "            if not SUBMIT:\n",
    "                plot_predictions_errors(y_test, y_test_pred, 'Test')\n",
    "\n",
    "    print('-'*80, end='\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and load out-of-fold predictions to avoid fitting again estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all dataframes of X_meta_trains and X_meta_hold_outs to csv seprarately\n",
    "for i in range(5):\n",
    "    X_meta_trains[i].to_csv(f'datasets/X_meta_trains_{i}.csv')\n",
    "    X_meta_hold_outs[i].to_csv(f'datasets/X_meta_hold_outs_{i}.csv')\n",
    "    X_meta_tests[i].to_csv(f'datasets/X_meta_tests_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes of X_meta_trains and X_meta_hold_outs from csv seprarately\n",
    "X_meta_trains_2, X_meta_hold_outs_2 = {}, {}\n",
    "for i in range(5):\n",
    "    X_meta_trains_2[i] = pd.read_csv(f'datasets/X_meta_trains_{i}.csv', index_col=0)\n",
    "    X_meta_hold_outs_2[i] = pd.read_csv(f'datasets/X_meta_hold_outs_{i}.csv', index_col=0)\n",
    "    X_meta_tests_2[i] = pd.read_csv(f'datasets/X_meta_tests_{i}.csv', index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For final predictions, use sklearn stacking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple stacking with sklearn without target transformation\n",
    "regressors = [\n",
    "    ('LGBMRegressor11', LGBMRegressor(random_state=SEED, n_jobs=1, boosting_type='gbdt', num_leaves=48, \n",
    "                                     max_depth=14, learning_rate=0.08, n_estimators=240, subsample=0.7, colsample_bytree=0.6)),\n",
    "    ('XGBRegressor6', XGBRegressor(random_state=SEED, n_jobs=-1, learning_rate=0.055, n_estimators=200,  \n",
    "                                  max_depth=8,  min_child_weight=1, gamma=0.07,  colsample_bytree=0.67, \n",
    "                                  colsample_bylevel=0.67, colsample_bynode=0.8, subsample=0.7, \n",
    "                                  objective='reg:squarederror')),\n",
    "    ('CatBoostRegressor', CatBoostRegressor(random_state=SEED, silent=True)),\n",
    "    ('HistGradientBoostingRegressor2', HistGradientBoostingRegressor(random_state=SEED, max_iter=1000, \n",
    "                                                                    max_depth=10, learning_rate=0.1, \n",
    "                                                                    l2_regularization=0.1, max_leaf_nodes=100, \n",
    "                                                                    min_samples_leaf=20, max_bins=255)),\n",
    "    \n",
    "]\n",
    "\n",
    "model = StackingRegressor(\n",
    "    estimators=regressors,\n",
    "    final_estimator=LinearRegression(cv=cv, max_iter=10000, n_jobs=-1),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "model.fit(X_train_prep, y_train)\n",
    "y_pred_StackingRegressor = model.predict(X_test_prep)\n",
    "\n",
    "# Save predictions\n",
    "sub = pd.read_csv('submissions/sample_submission.csv')\n",
    "sub['price'] = y_pred_StackingRegressor\n",
    "now = time.strftime(\"%Y-%m-%d %H_%M_%S\")\n",
    "sub.to_csv(f'submissions/submission_StackingRegressor{now}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "859e3dd19ab39644bae753c16b5c1b7ab0df5c949bc088093bb6b6108b74d185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
